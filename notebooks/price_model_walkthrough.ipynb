{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836710fd-1f8e-43a2-a68a-00c7c7f03f67",
   "metadata": {},
   "source": [
    "# Famine Alert Price Model Walkthrough\n",
    "\n",
    "\n",
    "## Method\n",
    "We illustrate the process of identifying price anomolies as a means of \n",
    "This is based on Baquedano:\n",
    "\"[Developing an indicator of price anomalies as an early warning tool: A compound growth approach](https://www.fao.org/3/i7550e/i7550e.pdf)\"\n",
    "Felix G. Baquedano. FAO, Rome, 2015.\n",
    "\n",
    "## Data\n",
    "As an illustration, we use food price data on Sudan from the FAO Food price monitoring tool:\n",
    "1. [FAO data](https://fpma.fao.org/giews/fpmat4/#/dashboard/tool/domestic) (FAO. 2025. Food Price Monitoring and Analysis Tool. Accessed on February 3, 2025. Licence: CC-BY-4.0.)\n",
    "2. We use [IMF CPI inflation data](https://www.imf.org/external/datamapper/PCPIPCH@WEO/WEOWORLD/SDN?year=2025) (Source: International Monetary Fund, \"Inflation rate, average consumer prices\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768e501-6c96-447a-9670-5838dc662654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "try: # identify if in colab to fix paths\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"colab identified.\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d82af6-5aa7-4c2e-b9cf-b620393e95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the repository to access the data\n",
    "\n",
    "!git clone https://github.com/aristotle-tek/famine-prediction.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0430f66-2f8d-480b-b357-7984066b39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB: # fix for paths in colab\n",
    "    base_path = Path('/content/famine-prediction')\n",
    "else:\n",
    "    try:\n",
    "        base_path = Path(__file__).resolve().parent.parent\n",
    "    except NameError:\n",
    "        base_path = Path.cwd().parent.parent\n",
    "print(\"Base path: \", base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574961d-2280-4f6a-8d42-d3a72c146e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(base_path)\n",
    "from src.price_models import (\n",
    "    compute_cgr, compute_volatility, adjust_cgr_for_volatility,\n",
    "    weighted_mean, weighted_std, compute_anomaly_score, classify_anomaly,\n",
    "    compute_gamma, combine_signals, handle_missing_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e56d0e-dc59-4b0c-b3c1-4fa2339ddb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# example - wheat - Sudan\n",
    "sudan_wheat_file = base_path / 'data'/ 'raw'/ 'price_data' / 'Sudan_Wheat_Mon_Feb_03_2025.xlsx'\n",
    "\n",
    "df = pd.read_excel(sudan_wheat_file, parse_dates=['Date'])\n",
    "df.sort_values(by='Date', inplace=True)\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# just rename to the region, since they are all for Wheat, Retail, SDG/Kg\n",
    "df.columns =  df.columns.str.extract(r'RETAIL, ([^,]+), Wheat Grain')[0].str.replace(\" \", \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4765e6-36b7-4e95-8528-31e45bfa8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now we will just use a single region & food as an example: Wheat prices in Al-Fashir\n",
    "\n",
    "curr_var = 'Al-Fashir'\n",
    "price_series = df[curr_var]\n",
    "\n",
    "missing = df[curr_var].isna().sum()\n",
    "total = len(df)\n",
    "print(f\"Missing values for {curr_var}: {missing}/{total} ({missing/total:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d0f62-5037-45cd-9f31-49ab802e6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some price data is missing, so we will interpolate it\n",
    "\n",
    "# print dates for which the price is missing\n",
    "print(df[df[curr_var].isna()].index)\n",
    "\n",
    "# Impute missing data using time-based interpolation (options include 'ffill', 'bfill', 'drop')\n",
    "price_series = handle_missing_data(price_series, method='interpolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d76dc-9b2b-4ff8-856a-6532ecad7ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now let's adjust for inflation\n",
    "\n",
    "inflation_index = pd.read_excel(base_path / 'price_data' / 'Sudan_IMF-inflation-20250203.xlsx', index_col=0)\n",
    "inflation_index.drop(columns=['Inflation rate, average consumer prices (Annual percent change)'], inplace=True)\n",
    "\n",
    "# The data is in rows, so transpose to get a column and set date as the index\n",
    "inflation_index = inflation_index.T\n",
    "\n",
    "inflation_index['Date'] = pd.to_datetime(inflation_index.index.astype(str) + '-01-01')\n",
    "\n",
    "# Set Date as index for easier merging\n",
    "inflation_index.set_index('Date', inplace=True)\n",
    "\n",
    "def adjust_for_inflation(price_series, inflation_series):\n",
    "    \"\"\"Adjusts price data for inflation using CPI index.\"\"\"\n",
    "    return price_series / inflation_series.reindex(price_series.index, method='ffill')\n",
    "\n",
    "\n",
    "price_series = adjust_for_inflation(price_series, inflation_index['Sudan'])\n",
    "\n",
    "print(price_series.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f1a34-3801-46cf-b586-d77e0e6c5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute compound growth rates\n",
    "\n",
    "# Compute CGR over a 3-month window (quarterly) and 12-month window (annual)\n",
    "df['CGR_3m'] = compute_cgr(price_series, window=3)\n",
    "df['CGR_12m'] = compute_cgr(price_series, window=12)\n",
    "\n",
    "# Compute volatility (rolling std of log differences) over the same windows\n",
    "df['vol_3m'] = compute_volatility(price_series, window=3)\n",
    "df['vol_12m'] = compute_volatility(price_series, window=12)\n",
    "\n",
    "# Adjust the CGRs for volatility\n",
    "df['vCGR_3m'] = adjust_cgr_for_volatility(df['CGR_3m'], df['vol_3m'])\n",
    "df['vCGR_12m'] = adjust_cgr_for_volatility(df['CGR_12m'], df['vol_12m'])\n",
    "\n",
    "# To put slightly more emphasis on more recent data, we create a simple \n",
    "# linear increasing weight varying from 1 to 2. \n",
    "weights = np.linspace(1, 2, len(df))\n",
    "\n",
    "# Compute weighted mean and standard deviation for the quarterly vCGR\n",
    "valid_mask_3m = df['vCGR_3m'].notna()\n",
    "valid_vCGR_3m = df.loc[valid_mask_3m, 'vCGR_3m'].values\n",
    "weights_3m = weights[valid_mask_3m]\n",
    "w_mean_3m = weighted_mean(valid_vCGR_3m, weights_3m)\n",
    "w_std_3m = weighted_std(valid_vCGR_3m, weights_3m)\n",
    "\n",
    "# Similarly for the annual vCGR\n",
    "valid_mask_12m = df['vCGR_12m'].notna()\n",
    "valid_vCGR_12m = df.loc[valid_mask_12m, 'vCGR_12m'].values\n",
    "weights_12m = weights[valid_mask_12m]\n",
    "w_mean_12m = weighted_mean(valid_vCGR_12m, weights_12m)\n",
    "w_std_12m = weighted_std(valid_vCGR_12m, weights_12m)\n",
    "\n",
    "# Compute anomaly scores for each period where vCGR is available\n",
    "df['IPA_score_3m'] = df['vCGR_3m'].apply(\n",
    "    lambda x: compute_anomaly_score(x, w_mean_3m, w_std_3m) if pd.notna(x) else np.nan\n",
    ")\n",
    "df['IPA_score_12m'] = df['vCGR_12m'].apply(\n",
    "    lambda x: compute_anomaly_score(x, w_mean_12m, w_std_12m) if pd.notna(x) else np.nan\n",
    ")\n",
    "\n",
    "# Classify each anomaly based on its score\n",
    "df['Alert_3m'] = df['IPA_score_3m'].apply(\n",
    "    lambda x: classify_anomaly(x) if pd.notna(x) else \"Insufficient data\"\n",
    ")\n",
    "df['Alert_12m'] = df['IPA_score_12m'].apply(\n",
    "    lambda x: classify_anomaly(x) if pd.notna(x) else \"Insufficient data\"\n",
    ")\n",
    "\n",
    "# Compute gamma from the available quarterly and annual vCGR values\n",
    "gamma = compute_gamma(df['vCGR_3m'].dropna(), df['vCGR_12m'].dropna())\n",
    "\n",
    "# Combine the quarterly and annual anomaly scores where both are available\n",
    "def combined_IPA(row):\n",
    "    if pd.notna(row['IPA_score_3m']) and pd.notna(row['IPA_score_12m']):\n",
    "        return combine_signals(row['IPA_score_3m'], row['IPA_score_12m'], gamma)\n",
    "    return np.nan\n",
    "\n",
    "df['IPA_combined'] = df.apply(combined_IPA, axis=1)\n",
    "df['Alert_combined'] = df['IPA_combined'].apply(\n",
    "    lambda x: classify_anomaly(x) if pd.notna(x) else \"Insufficient data\"\n",
    ")\n",
    "\n",
    "print(df[[\n",
    "    curr_var, 'CGR_3m', 'CGR_12m', 'vCGR_3m', 'vCGR_12m',\n",
    "    'IPA_score_3m', 'IPA_score_12m', 'IPA_combined',\n",
    "    'Alert_3m', 'Alert_12m', 'Alert_combined'\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1727f6d-015a-4eda-8270-a06b35e445ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test stationarity\n",
    "\n",
    "from src.stationarity_tests import test_adf, test_pp, test_dfgls, test_kpss\n",
    "\n",
    "\n",
    "adf_result = test_adf(price_series)\n",
    "pp_result = test_pp(price_series)\n",
    "dfgls_result = test_dfgls(price_series)\n",
    "kpss_result = test_kpss(price_series)\n",
    "\n",
    "print(\"ADF Test:\", adf_result)\n",
    "print(\"\\n\\nPhillips-Perron Test:\", pp_result)\n",
    "print(\"\\n\\nDF-GLS Test:\", dfgls_result)\n",
    "print(\"\\n\\nKPSS Test:\", kpss_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9775f-e7a8-49a3-8c6f-0edbf8320967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simplify the interpretation of the tests, we can re-organize the output\n",
    "\n",
    "def summarize_stationarity_tests(adf_result, pp_result, dfgls_result, kpss_result):\n",
    "    summary = {}\n",
    "\n",
    "    adf_stat = adf_result['Test Statistic']\n",
    "    adf_pval = adf_result['p-value']\n",
    "    adf_critical = adf_result['Critical Values']\n",
    "    if adf_stat < adf_critical['10%'] and adf_pval < 0.05:\n",
    "        summary['ADF Test'] = \"Suggests Stationarity\"\n",
    "    else:\n",
    "        summary['ADF Test'] = \"Suggests Non-Stationarity\"\n",
    "\n",
    "    pp_stat = pp_result['Test Statistic']\n",
    "    pp_pval = pp_result['p-value']\n",
    "    pp_critical = pp_result['Critical Values']\n",
    "    if pp_stat < pp_critical['10%'] and pp_pval < 0.05:\n",
    "        summary['Phillips-Perron Test'] = \"Suggests Stationarity\"\n",
    "    else:\n",
    "        summary['Phillips-Perron Test'] = \"Suggests Non-Stationarity\"\n",
    "\n",
    "    dfgls_stat = dfgls_result['Test Statistic']\n",
    "    dfgls_pval = dfgls_result['p-value']\n",
    "    dfgls_critical = dfgls_result['Critical Values']\n",
    "    if dfgls_stat < dfgls_critical['10%'] and dfgls_pval < 0.05:\n",
    "        summary['DF-GLS Test'] = \"Suggests Stationarity\"\n",
    "    else:\n",
    "        summary['DF-GLS Test'] = \"Suggests Non-Stationarity\"\n",
    "\n",
    "    # KPSS (opposite null hypothesis)\n",
    "    kpss_stat = kpss_result['Test Statistic']\n",
    "    kpss_critical = kpss_result['Critical Values']\n",
    "    if kpss_stat < kpss_critical['1%']:\n",
    "        summary['KPSS Test'] = \"Suggests Stationarity\"\n",
    "    else:\n",
    "        summary['KPSS Test'] = \"Suggests Non-Stationarity\"\n",
    "\n",
    "    return summary\n",
    "\n",
    "summary_results = summarize_stationarity_tests(adf_result, pp_result, dfgls_result, kpss_result)\n",
    "for test, result in summary_results.items():\n",
    "    print(f\"{test}: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
